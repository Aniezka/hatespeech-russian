{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"dk65Pn1tVtKu"},"outputs":[],"source":["!pip install tokenizers\n","!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2vqdcoVfL89C"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","import pandas as pd\n","import numpy as np\n","import torch\n","from tqdm.auto import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nSNratqSVqWl"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3large_based_on_gpt2\")\n","model = AutoModelForCausalLM.from_pretrained(\"sberbank-ai/rugpt3large_based_on_gpt2\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mpTqNgF1VqZI"},"outputs":[],"source":["def find_perplexity(text_1, text_2):\n","    input_ids1 = tokenizer(text_1, return_tensors='pt')['input_ids']\n","    input_ids2 = tokenizer(text_2, return_tensors='pt')['input_ids']\n","\n","    with torch.no_grad():\n","        loss_1 = model(input_ids=input_ids1, labels=input_ids1).loss\n","        loss_2 = model(input_ids=input_ids2, labels=input_ids2).loss\n","\n","    perplexity_1 = np.exp(loss_1)\n","    perplexity_2 = np.exp(loss_2) \n","\n","    if perplexity_1 < perplexity_2:\n","        model_choice = 'toxic original'\n","    else: \n","        model_choice = 'API non-toxic version'\n","\n","    return perplexity_1, perplexity_2, model_choice\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pogoFDf4kQBL"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3-z084OKVqbM"},"outputs":[],"source":["data = pd.read_csv('rubert.csv')\n","original_dialogues = [x+' '+y for x,y in zip(data['Реплика 1 toxicity'], data['Реплика 2 toxicity'])]\n","API_dialogues = [x+' '+y for x,y in zip(data['Реплика 1 toxicity'], data['Реплика 2 original dialogue 1'])]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":407,"referenced_widgets":["696e58e7bca145a2bbfd570de73994a4"]},"executionInfo":{"elapsed":744864,"status":"error","timestamp":1653576883380,"user":{"displayName":"Анна Палаткина","userId":"04953591887011095861"},"user_tz":-120},"id":"BGDYLjcWVqdy","outputId":"83d21058-cb03-4fd5-84fa-74176fde753d"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"696e58e7bca145a2bbfd570de73994a4","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["perplexities_1 = []\n","perplexities_2 = []\n","model_choices = []\n","\n","\n","for text_1, text_2 in tqdm(zip(original_dialogues, API_dialogues)):\n","    perplexity_1, perplexity_2, model_choice = find_perplexity(text_1, text_2)\n","    perplexities_1.append(perplexity_1)\n","    perplexities_2.append(perplexity_2)\n","    model_choices.append(model_choice)\n","\n","data['perplexity_original_toxic'] = perplexities_1\n","data['perplexity_API_non_toxic'] = perplexities_2\n","data['GPT_choice'] = model_choices"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NuuAHwWNVqfo"},"outputs":[],"source":["data.to_csv('rubert_gpt3_balanced.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RNnb7376Vq-d"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2pqyAHuJVrAs"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"name":"gpt_3.ipynb","provenance":[],"authorship_tag":"ABX9TyM99iMxVPrqfTBwTJHs2EMG"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{}}},"nbformat":4,"nbformat_minor":0}