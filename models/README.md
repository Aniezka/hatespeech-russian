# Testing the Models
- rubert.ipynb - training of RuBERT (Russian, cased, 12 - layer, 768- hidden, 12- heads, 180M parameters was trained on the Russian part of Wikipedia and news data)
- rubert_model_ev.ipynb - classification report for RuBert
- rubert_xl.py - Conversational RuBERT7 (Russian, cased, 12- layer, 768- hidden, 12 - heads, 180M parameters was trained on OpenSubtitles, Dirty, Pikabu, and a Social Media segment of Taiga corpus)
- gpt_3.ipynb - RuGPT3 Large 
- GPT3NEW.ipynb - !(RuGPT3 XL)[https://huggingface.co/sberbank-ai/rugpt3xl]

Link to data: https://disk.yandex.ru/d/-tCsNY__X1yyvA 
